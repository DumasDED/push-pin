Break the string into constituents:

'Bushwick, Brooklyn, NY' --> ['Bushwick', 'Brooklyn', 'NY']


Starting at the END of the array, search for a state:

data.find_state('NY') --> <Location.NewYork>

- What if it returns two states?
- What if it doesn't return any state?


Once that's been found, take the previous string in the array
and use it to find a city in that state:

state<Location.NewYork>.find_city('Brooklyn') --> <Location.NewYork.Brooklyn>


IF IT CAN'T FIND A STATE:
- Using the first string, search the dataset for matching locations
- Store the matching admin code combinations in an array
- Iterate through the remaining strings:
    - Search the dataset for matching locations
    - Compare admin codes to what is already in the stored array
    - Eliminate any combinations that are not common to the result set
- If the array is reduced to zero, fail
- If the array is reduced to more than one, repeat the process using exact
  matches instead of approximate ones


Need this enum somewhere.

class FeatureClass:
    ADM1 = 1
    ADM2 = 2
    ADM3 = 3
    ADMD = 4
    PPLC = 5
    PPLG = 6
    PPLA = 7
    PPLA2 = 8
    PPLA3 = 9
    PPLA4 = 10
    PPL = 11
    PPLX = 12
    PPLS = 13
    PPLL = 14



My methodology needs work.

The problem with what I'm doing now is that I'm utilizing the entire search
string to look for both a state and a city. That means that, for a search string
of "Brooklyn, New York", the list of possible cities includes all matches for
"Brooklyn" AND all matches for "New York". That's a lot more cities than I need,
and in fact when I do it that way and then pick the highest administrative level
out of those left, I end up getting Albany, NY.

What I need to do instead: there are a limited number of states. Those should be
very easy to match by comparison. I need to find a state first, and then REMOVE
THE STRING THAT MATCHES THE STATE from the search string. Thus, once I've found
a match for the state of New York, I need to reduce my search string so that it
only includes "Brooklyn".

OK. That's done.

With states a more fail-fast approach is feasible because there are few enough
states that I can realistically expect to match either one or none. With cities,
however, there are likely to be several matches for a given search string, and
conceivably any one of them could be the name of the actual city. Or it could be
that none of them are the name of the city.

The original strategy I had in mind is to cross-reference the results produced by
any given search string and only retain the intersection of admin codes between
them. So for example, if the results of "Bushwick" return three results and the
results of "Brooklyn" return two results, and one result from each of those sets
includes a location with an admin code of "NY.047", retain both of those results
and discard the rest.

Right now all I'm doing is just accumulating all the matches. That's not practical
by comparison. I need to at least eliminate some of them.

I think what I was originally doing (or intending to do) was to accumulate all
the potential candidates, count the occurrences of each admin code, and keep
only those options which corresponded to the most common admin code (or codes,
though hopefully not more than one).

At this point the algorithm is pretty robust. It can successfully narrow down
most of the searches I throw at it. It can deduce Brooklyn from just "Brooklyn".
It can find Berkeley without assuming it means Oakland. It can find Highland Park,
though it finds two different instances of it.

One of the most glaring inaccuracies at this point is "Richmond, VA". This returns
Warsaw, VA, for some reason, which I think has to do with the fact that the admin
code associated with Warsaw happens to be more frequent than that for the city of
Richmond itself, and because Warsaw is the highest administrative division for that
admin code, that's what gets selected. This would seem to indicate that the most
frequent admin code is not always a safe bet.

These are the cities that the search algorithm first finds:

        Port Richmond VA.101 PPL
        Richmond VA.760 PPLA
        South Richmond VA.159 PPL
        Warsaw VA.159 PPLA2

These results would suggest that I should be filtering by similarities in names. I
could see this being a potential use for fuzzy matching, but that could mean comparing
every city name to every other city name, which seems cumbersome.

Alternatively I could do a fuzzy compare of city names to the search string, but
I don't love the idea of going back to the search string.

itertools has a combinations function that will pair up elements of a list into
unique combinations. That could be a really efficient means of comparing every
name to every other name. Then I could use fuzzywuzzy to do partial ratio matches
and score each city for each ratio.

>>> fuzz.partial_ratio('Richmond', 'South Richmond')
100
>>> fuzz.partial_ratio('Warsaw', 'South Richmond')
0
>>> fuzz.partial_ratio('Warsaw', 'Richmond')
0

In this case Warsaw would cumulatively receive a score of zero, while the others
would receive cumulative scores well above 100. From that logic I could simply discard
everything with a 0 score and keep the rest. That seems dangerous, though, and in
any case that's only really applicable in this context - I don't know that it will
be applicable in other contexts.

Time for bed anyway.